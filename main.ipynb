{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "from utils import GroundTruthProcess\n",
    "from utils import NCHW_to_NHWC_np\n",
    "from utils import NHWC_to_NCHW_np\n",
    "from DME_deformable import DMENet\n",
    "from config import DefaultConfig\n",
    "import torch.cuda as torch_cudab\n",
    "import metrics\n",
    "MAE = 10240000\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the gpu device\n",
    "assert torch.cuda.is_available()\n",
    "cuda_device = torch.device(\"cuda\")  # device object representing GPU\n",
    "opt = DefaultConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_load\n",
    "image_train = NHWC_to_NCHW_np(np.load(opt.train_data_path))\n",
    "gt_train = NHWC_to_NCHW_np(np.load(opt.train_gt_path))\n",
    "image_validate = NHWC_to_NCHW_np(np.load(opt.validate_data_path))\n",
    "gt_validate = NHWC_to_NCHW_np(np.load(opt.validate_gt_path))\n",
    "\n",
    "image_train_num = len(image_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model construct\n",
    "net = DMENet().to(cuda_device)\n",
    "gt_map_process_model = GroundTruthProcess(1, 1, 8).to(cuda_device) # to keep the same resolution with the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set optimizer and estimator\n",
    "criterion = metrics.DMELoss().to(cuda_device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=opt.lr, weight_decay=opt.weight_decay)\n",
    "ae_batch = metrics.AEBatch().to(cuda_device)\n",
    "se_batch = metrics.SEBatch().to(cuda_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'opt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-22b040b83e36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mshuffle_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_train_num\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_train_num\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'opt' is not defined"
     ]
    }
   ],
   "source": [
    "# train\n",
    "for i in range(opt.max_epoch):\n",
    "    shuffle_batch = np.random.permutation(image_train_num // opt.batch_size)\n",
    "    step = 0\n",
    "    for j in range(image_train_num // opt.batch_size):\n",
    "        # validate\n",
    "        net.eval()\n",
    "        if step % opt.validate_steps == 0:\n",
    "            loss_ = []\n",
    "            MAE_ = []\n",
    "            MSE_ = []\n",
    "            \n",
    "            # gather all validate information\n",
    "            for k in range(len(image_validate // opt.batch_size)):\n",
    "                if opt.use_gpu:\n",
    "                    validate_x = torch.FloatTensor(image_validate[k:k + opt.batch_size]).cuda()\n",
    "                    validate_gt = torch.FloatTensor(gt_validate[k:k + opt.batch_size]).cuda()\n",
    "                validate_predict_map = net(validate_x)\n",
    "                validate_gt_map = gt_map_process_model(validate_gt)\n",
    "                # That’s because numpy doesn’t support CUDA, \n",
    "                # so there’s no way to make it use GPU memory without a copy to CPU first. \n",
    "                # Remember that .numpy() doesn’t do any copy, \n",
    "                # but returns an array that uses the same memory as the tensor\n",
    "                validate_loss = criterion(validate_predict_map, validate_gt_map).data.cpu().numpy()\n",
    "                batch_ae = ae_batch(validate_predict_map, validate_gt_map).data.cpu().numpy()\n",
    "                batch_se = se_batch(validate_predict_map, validate_gt_map).data.cpu().numpy()\n",
    "                loss_.append(validate_loss)\n",
    "                MAE_.append(batch_ae)\n",
    "                MSE_.append(batch_se)\n",
    "            \n",
    "            # calculate the validate loss, validate MAE and validate RMSE\n",
    "            loss_ = np.reshape(loss_, [-1])\n",
    "            MAE_ = np.reshape(MAE_, [-1])\n",
    "            MSE_ = np.reshape(MSE_, [-1])\n",
    "            \n",
    "            validate_loss = np.mean(loss_)\n",
    "            validate_MAE = np.mean(MAE_)\n",
    "            validate_RMSE = np.sqrt(np.mean(MSE_))\n",
    "            \n",
    "            # show one sample from the validation\n",
    "#             random_num = random.randint(0, 19)\n",
    "            random_num = 1\n",
    "            random_sample_x = torch.FloatTensor(image_validate[random_num:random_num+1]).cuda()\n",
    "            random_sample_gt = torch.FloatTensor(gt_validate[random_num:random_num+1]).cuda()\n",
    "            random_sample_predict = NCHW_to_NHWC_np(net(random_sample_x).data.cpu().numpy())\n",
    "            random_sample_gt_map = NCHW_to_NHWC_np(gt_map_process_model(random_sample_gt).data.cpu().numpy())\n",
    "            \n",
    "            figure, (origin, density_gt, pred) = plt.subplots(1, 3, figsize=(20, 4))\n",
    "            origin.imshow(np.squeeze(NCHW_to_NHWC_np(image_validate[random_num:random_num+1])))\n",
    "            origin.set_title('Origin Image')\n",
    "            density_gt.imshow(np.squeeze(random_sample_gt_map), cmap=plt.cm.jet)\n",
    "            density_gt.set_title('ground_truth')\n",
    "            pred.imshow(np.squeeze(random_sample_predict), cmap=plt.cm.jet)\n",
    "            pred.set_title('back_end')\n",
    "            plt.suptitle(\"one sample from the validate\")\n",
    "            plt.show()\n",
    "            \n",
    "            # show the validate MAE and MSE values on stdout\n",
    "            gt_counts = np.squeeze(torch.sum(validate_gt_map, dim=(0, 1, 2, 3)).data.cpu().numpy())\n",
    "            pred_counts = np.squeeze(torch.sum(validate_predict_map, dim=(0, 1, 2, 3)).data.cpu().numpy())\n",
    "            sys.stdout.write('The gt counts of the above sample:{}, and the pred counts:{}\\n'.format(gt_counts, pred_counts))\n",
    "            sys.stdout.write('In step {}, epoch {}, with loss {}, MAE = {}, MSE = {}\\n'.format(step, i + 1, validate_loss, validate_MAE, validate_RMSE))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            # save model\n",
    "            if MAE > validate_MAE:\n",
    "                MAE = validate_MAE\n",
    "                torch.save(net, opt.model_save_path)\n",
    "            \n",
    "        \n",
    "        # clear the gradient\n",
    "        net.train()\n",
    "        optimizer.zero_grad()\n",
    "        # get the batch data\n",
    "        start = (shuffle_batch[j] * opt.batch_size) % image_train_num\n",
    "        end = min(start + opt.batch_size, image_train_num)\n",
    "        if opt.use_gpu:\n",
    "            x = torch.FloatTensor(image_train[start:end]).cuda()\n",
    "            gt = torch.FloatTensor(gt_train[start:end]).cuda()\n",
    "        # processs the gt because the final output only have 1/8 resolution\n",
    "        gt_map = gt_map_process_model(gt)\n",
    "        # flow the data through the net\n",
    "        estimated_density_map = net(x)\n",
    "        # calculate the loss and backward the gradient\n",
    "        loss = criterion(estimated_density_map, gt_map)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        step += 1\n",
    "            \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4242,  0.7217,  1.1008],\n",
      "        [-0.0442, -0.6967,  0.4862]]) tensor([[ 0.0191,  1.7691,  0.8167],\n",
      "        [-1.4132, -0.5933,  0.9567]])\n",
      "tensor([[0.0081, 1.2768, 0.8991],\n",
      "        [0.0624, 0.4133, 0.4651]])\n",
      "tensor([[0.1800, 0.5209, 1.2118],\n",
      "        [0.0020, 0.4853, 0.2364]])\n",
      "tensor(-3.2035)\n",
      "tensor(-1.6017)\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 3)\n",
    "b = torch.randn(2, 3)\n",
    "print(a, b)\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23107249000000002\n"
     ]
    }
   ],
   "source": [
    "print(0.4807 * 0.4807)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    }
   ],
   "source": [
    "# optimizer = torch.optim.Adam()\n",
    "print(len(list(net.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(list(net.children())[1])[0]\n",
    "b = list(list(a.children())[0].children())[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.56534958 0.24370027 0.72369011 0.67889216 0.04249182]\n",
      "   [0.00842371 0.48885883 0.21877356 0.75751709 0.55534385]\n",
      "   [0.21609105 0.38360997 0.69587199 0.57972236 0.37004643]\n",
      "   [0.77530353 0.21747802 0.84950338 0.1185008  0.06807957]]\n",
      "\n",
      "  [[0.00871294 0.36645846 0.45530013 0.104406   0.56377999]\n",
      "   [0.48795602 0.76807449 0.06316015 0.01205147 0.9723964 ]\n",
      "   [0.23015443 0.01537153 0.98212864 0.04200032 0.20598123]\n",
      "   [0.76175589 0.60508917 0.8725611  0.8562562  0.02366146]]\n",
      "\n",
      "  [[0.6246715  0.16085285 0.43329321 0.18251999 0.04658025]\n",
      "   [0.83781238 0.86846604 0.46351249 0.16919308 0.50824695]\n",
      "   [0.35417069 0.84248133 0.80769374 0.41581033 0.23163003]\n",
      "   [0.81354884 0.64415368 0.27507783 0.01011959 0.18384952]]]] (1, 3, 4, 5)\n",
      "[[[[0.56534958 0.00871294 0.6246715 ]\n",
      "   [0.24370027 0.36645846 0.16085285]\n",
      "   [0.72369011 0.45530013 0.43329321]\n",
      "   [0.67889216 0.104406   0.18251999]\n",
      "   [0.04249182 0.56377999 0.04658025]]\n",
      "\n",
      "  [[0.00842371 0.48795602 0.83781238]\n",
      "   [0.48885883 0.76807449 0.86846604]\n",
      "   [0.21877356 0.06316015 0.46351249]\n",
      "   [0.75751709 0.01205147 0.16919308]\n",
      "   [0.55534385 0.9723964  0.50824695]]\n",
      "\n",
      "  [[0.21609105 0.23015443 0.35417069]\n",
      "   [0.38360997 0.01537153 0.84248133]\n",
      "   [0.69587199 0.98212864 0.80769374]\n",
      "   [0.57972236 0.04200032 0.41581033]\n",
      "   [0.37004643 0.20598123 0.23163003]]\n",
      "\n",
      "  [[0.77530353 0.76175589 0.81354884]\n",
      "   [0.21747802 0.60508917 0.64415368]\n",
      "   [0.84950338 0.8725611  0.27507783]\n",
      "   [0.1185008  0.8562562  0.01011959]\n",
      "   [0.06807957 0.02366146 0.18384952]]]] (1, 4, 5, 3)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(1, 3, 4 ,5)\n",
    "print(x, x.shape)\n",
    "x = np.swapaxes(x, 1, 2)\n",
    "x = np.swapaxes(x, 2, 3)\n",
    "print(x, x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
